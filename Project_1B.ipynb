{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline for Sparkify Apache Cassandra Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Create Apache Cassandra Tables and Insert Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in the CSV is comprised of the following columns and datatype:\n",
    "\n",
    "| Field                     | Data Type  |\n",
    " |------------------------  | ---------- |\n",
    "| artist                    | text       |\n",
    "| firstname                 | text       |\n",
    "| gender                    | text       |\n",
    "| item number in session    | int        |\n",
    "| last name of user         | text       |\n",
    "| length of the song        | float      |\n",
    "| level (paid or free song) | text       |\n",
    "| location of the user      | text       |\n",
    "| sessionId                 | int        |\n",
    "| song title                | text       |\n",
    "| userId                    | int        |\n",
    "\n",
    "Below is a screenshot of the csv\n",
    "\n",
    "![top five](./images/image_event_datafile_new.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create Cluster, Keyspacae, and set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Cluster\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['127.0.0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the cluster and establish a session\n",
    "cluster = Cluster(['127.0.0.1'])\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Keyspace\n",
    "session.execute(\"\"\"\n",
    "CREATE KEYSPACE IF NOT EXISTS sparkifydb \n",
    "WITH REPLICATION = \n",
    "{ 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Keyspace\n",
    "session.set_keyspace('sparkifydb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Create Table, which upon query will return artist, song title, song's length during a session and item in session. (Query 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Create table.\n",
    "Primary Key is the sessionId and the itemInSession.  These fields are the fields which will be queried against, as such they were desginated as the Primary Key.  The remaining fields were created in order based upon thier usage.  For example, the query given asks to return the artist, song title, and song length, these are created after the Primary Key fields of sessionID and itemInSession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS music_by_seesionId \"\n",
    "query = query + \"(artist text, firstName text, gender text, itemInSession int, lastName text, length float, level text, location text, sessionId int, song text, userId int, PRIMARY KEY (sessionId, itemInSession))\"\n",
    "session.execute(query)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Insert data into table, inserts are ordered from Primary Keys to expected query select fields to the reaming fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the datasete\n",
    "df= pd.read_csv('event_datafile_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the query\n",
    "query = \"INSERT INTO music_by_seesionId (sessionId, itemInSession, artist, song, length, firstName, gender, lastName, level, location, userId)\"\n",
    "query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the data into the table\n",
    "for index, row in df.iterrows():\n",
    "    session_data = [row['sessionId'], row['itemInSession'], row['artist'], row['song'], row['length'], row['firstName'], row['gender'], row['lastName'], row['level'], row['location'], row['userId']]\n",
    "    session.execute(query, session_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Query the music_by_sesssionID to see if it returns the expected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the query\n",
    "query = \" select artist, song, length, location from music_by_seesionId WHERE sessionid=338 and iteminsession=4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query and view the results in a dataframe\n",
    "qdf = pd.DataFrame(list(session.execute(query)))\n",
    "qdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Create Table, which upon query will return the artist, song (sorted by itemInSession) and user (firstName and lastName) based on userId and sessionId. (Query 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Create table.\n",
    "Primary Key is the uderId and sessionId with a clustering key of itemInSession.  These fields are the fields which will be queried against, as such they were desginated as the Primary Key.  The remaining fields were created in order based upon thier usage.  For example, the query given asks to return the artist, song title, and user, these are created after the Primary Key fields of sessionID and itemInSession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS music_by_userid \"\n",
    "query = query + \"(userId int, sessionId int, itemInSession int, artist text, song text, firstName text, lastName text, length float, gender text, level text, location text, PRIMARY KEY ((userId, sessionId), itemInSession))\"\n",
    "session.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Insert data into table, inserts are ordered from Primary Keys to clustering key to expected query select fields to the reaming fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset\n",
    "df= pd.read_csv('event_datafile_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the query\n",
    "query = \"INSERT INTO music_by_userid ( userId, sessionId, itemInSession, artist, song, firstName, lastName, length, gender, level, location)\"\n",
    "query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the data into the table\n",
    "for idex, row in df.iterrows():\n",
    "    session_data = [row['userId'], row['sessionId'], row['itemInSession'], row['artist'], row['song'], row['firstName'], row['lastName'], row['length'], row['gender'], row['level'], row['location']]\n",
    "    session.execute(query, session_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.3 Query the music_by_userid to see if it returns the expected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the query\n",
    "query = \" select artist, song, firstName, lastName from music_by_userid WHERE userId=10 and sessionid = 182 \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query and view the results in a dataframe\n",
    "qdf = pd.DataFrame(list(session.execute(query)))\n",
    "qdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Create Table, which upon query will return the first and last name of a user who has listened to a song (Query 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.1 Create table.\n",
    "Primary Key is the songId and userId.  The songId is the will be queried against, but to make it unquie the userId needs to be added to make it a composite key, as such they were desginated as the Primary Key.  The remaining fields were created in order based upon thier usage.  For example, the query given asks to return the artist, song title, and user, these are created after the Primary Key fields of sessionID and itemInSession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS userinfo_by_song \"\n",
    "query = query + \"(song text, userId int, firstName text, lastName text, sessionId int, itemInSession int, artist text, length float, gender text, level text, location text, PRIMARY KEY (song, userId))\"\n",
    "session.execute(query) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.2 Insert data into table, inserts are ordered from Primary Keys to clustering key to expected query select fields to the reaming fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset\n",
    "df= pd.read_csv('event_datafile_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the query\n",
    "query = \"INSERT INTO userinfo_by_song ( song, userId, firstName, lastName, sessionId, itemInSession, artist, length, gender, level, location)\"\n",
    "query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the data into the table\n",
    "for idex, row in df.iterrows():\n",
    "    session_data = [row['song'], row['userId'], row['firstName'], row['lastName'], row['sessionId'], row['itemInSession'], row['artist'], row['length'], row['gender'], row['level'], row['location']]\n",
    "    session.execute(query, session_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.3 Query the userinfo_by_song to see if it returns the expected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the query\n",
    "query = \" select firstName, lastName from userinfo_by_song WHERE song='All Hands Against His Own' \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query and view the results in a dataframe\n",
    "qdf = pd.DataFrame(list(session.execute(query)))\n",
    "qdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Drop Tables and close session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"drop table music_by_seesionId\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query = \"drop table music_by_userid\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query = \"drop table userinfo_by_song\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close the session and cluster connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
